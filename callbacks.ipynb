{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor, nn, optim\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, model, optimizer, loss_func, train_data, valid_data):\n",
    "        self.model = model\n",
    "        self.opt = optimizer\n",
    "        self.loss_function = loss_func\n",
    "        self.train_dl = train_data\n",
    "        self.valid_dl = valid_data\n",
    "        return True\n",
    "    \n",
    "    def after_fit(self):\n",
    "        return True\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        return True\n",
    "    \n",
    "    def begin_validate(self):\n",
    "        return True\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        return True\n",
    "    \n",
    "    def begin_batch(self, x_batch, y_batch):\n",
    "        self.x_mini_batch = x_batch\n",
    "        self.y_mini_batch = y_batch\n",
    "        return True\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    \n",
    "    def after_backward(self):\n",
    "        return True\n",
    "    def after_step(self):\n",
    "        return True\n",
    "    \n",
    "class CallbackHandler():\n",
    "    def __init__(self, cbs=None):\n",
    "        self.callbacks = cbs if cbs else []\n",
    "        \n",
    "    def begin_fit(self, model, opt, loss_func, train_dl, valid_dl):\n",
    "        self.model = model\n",
    "        self.optimizer = opt\n",
    "        self.loss_function = loss_func\n",
    "        self.train_dataloader = train_dl\n",
    "        self.valid_dataloader = valid_dl\n",
    "        self.in_train = True #flag for if in training or evaluation\n",
    "        self.stop = False #flag that gets thrown to stop the model training\n",
    "        res = True\n",
    "        for cb in self.callbacks:\n",
    "            res = res and callbacks.begin_fit(model, opt, loss_func, train_dl ,valid_dl)\n",
    "        return res\n",
    "    \n",
    "    def after_fit(self):\n",
    "        result = not self.in_train\n",
    "        for cb in self.callbacks:\n",
    "            result = result and callbacks.after_fit()\n",
    "        return result\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        self.in_train = True\n",
    "        result = True\n",
    "        for cb in self.callbacks:\n",
    "            result = result and callbacks.begin_epoch(epoch)\n",
    "        return result\n",
    "    \n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.in_train = False\n",
    "        result = True\n",
    "        for cb in self.callbacks:\n",
    "            result = result and callbacks.begin_validate()\n",
    "        return result\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        result = True\n",
    "        for cb in self.callbacks:\n",
    "            result = result and cb.after_epoch()\n",
    "        return result\n",
    "    \n",
    "    def begin_batch(self, x_batch, y_batch):\n",
    "        result = True\n",
    "        for cb in self.cbs:\n",
    "            result = result and cb.begin_batch(xb, yb)\n",
    "        return result\n",
    "    \n",
    "    def after_loss(self, loss):\n",
    "        result = self.in_train\n",
    "        for cb in self.callbacks:\n",
    "            result = result and cb.after_loss(loss)\n",
    "        return result\n",
    "            \n",
    "    def after_backward(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_step()\n",
    "        return res\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     return self.learn.stop\n",
    "        finally: self.learn.stop = False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining fit()\n",
    "def one_batch(x_minib, y_minib, callbacks):\n",
    "    if not callbacks.begin_batch(xb,yb):\n",
    "        return\n",
    "    loss = callbacks.loss_function(callbacks.model(x_minib), y_minib)\n",
    "    if not callbacks.after_loss(loss):\n",
    "        return\n",
    "    loss.backward()\n",
    "    if callbacks.after_backward(): \n",
    "        callbacks.opt.step()\n",
    "    if callbacks.after_step():\n",
    "        callbacks.opt.zero_grad()\n",
    "    \n",
    "def all_batches(dataloader, callbacks):\n",
    "    for x_minib, y_minib in dataloader:\n",
    "        one_batch(x_minib, y_minib, callbacks)\n",
    "        if callbacks.do_stop():\n",
    "            return\n",
    "    \n",
    "def fit(num_epochs, model, optimizer, loss_func, train_dataloader, valid_dataloader):\n",
    "    if not callbacks.begin_fit(model, optimizer, loss_func, train_dataloader, valid_datalader):\n",
    "        return\n",
    "    for epoch in range(num_epochs):\n",
    "        if not callbacks.begin_epoch(epoch):\n",
    "            continue\n",
    "        all_batches(train_dataloader, callbacks)\n",
    "        \n",
    "        if callbacks.begin_validate():\n",
    "            with torch.no_grad():\n",
    "                all_batches(valid_dataloader, callbacks)\n",
    "        if callbacks.do_stop() or not callbacks.after_epoch():\n",
    "            break\n",
    "        callbacks.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def begin_fit(self,learn):\n",
    "        super().begin_fit(learn)\n",
    "        self.n_iters = 0\n",
    "        return True\n",
    "        \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=10: self.learn.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple 3 layer example model\n",
    "def get_model(training_data, lr=0.5, nh=50):\n",
    "    m = training_data.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'CrossEntropyLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ddcdb3c877ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnumber_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'CrossEntropyLoss'"
     ]
    }
   ],
   "source": [
    "number_hidden = 50\n",
    "batch_size = 64\n",
    "loss_func = F.CrossEntropyLoss\n",
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "\n",
    "#setup data\n",
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_dataset, batch_size, shuffle=False)\n",
    "model, optimizer = get_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a39d403df0ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCallbackHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTestCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "fit(1, model, optimizer, loss_func, train_dl, valid_dl, cb=CallbackHandler([TestCallback()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
