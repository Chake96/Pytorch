{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import datasets\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "import pickle, gzip, math, torch, re, matplotlib as mpl, matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from typing import Iterable\n",
    "from torch import tensor, nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x_ds, y_ds):\n",
    "        self.x_dataset = x_ds\n",
    "        self.y_dataset = y_ds\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_dataset)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x_dataset[i],self.y_dataset[i]\n",
    "\n",
    "class Callback():\n",
    "    def begin_fit(self, model, optimizer, loss_func, train_data, valid_data):\n",
    "        self.model = model\n",
    "        self.opt = optimizer\n",
    "        self.loss_function = loss_func\n",
    "        self.train_dl = train_data\n",
    "        self.valid_dl = valid_data\n",
    "        self.stop = False\n",
    "        return True\n",
    "    \n",
    "    def after_fit(self):\n",
    "        return True\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        return True\n",
    "    \n",
    "    def begin_validate(self):\n",
    "        return True\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        return True\n",
    "    \n",
    "    def begin_batch(self, x_batch, y_batch):\n",
    "        self.x_mini_batch = x_batch\n",
    "        self.y_mini_batch = y_batch\n",
    "        return True\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    \n",
    "    def after_backward(self):\n",
    "        return True\n",
    "    def after_step(self):\n",
    "        return True\n",
    "    \n",
    "class CallbackHandler():\n",
    "    def __init__(self,cbs=None):\n",
    "        self.cbs = cbs if cbs else []\n",
    "\n",
    "    def begin_fit(self, model,optimizer, loss_func, train_data, valid_data):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_func\n",
    "        self.train_dl = train_data\n",
    "        self.valid_dl = valid_data\n",
    "        self.stop = False\n",
    "        self.in_train = True\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "                res = res and cb.begin_fit(model,optimizer, loss_func, train_dl, valid_dl)\n",
    "        return res\n",
    "\n",
    "    def after_fit(self):\n",
    "        res = not self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_fit()\n",
    "        return res\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        self.in_train=True\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
    "        return res\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.in_train=False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_validate()\n",
    "        return res\n",
    "\n",
    "    def after_epoch(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_epoch()\n",
    "        return res\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
    "        return res\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        res = self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
    "        return res\n",
    "\n",
    "    def after_backward(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: \n",
    "            res = res and cb.after_step()\n",
    "            self.stop = cb.stop\n",
    "            if self.stop is False:\n",
    "                break\n",
    "        return res\n",
    "    \n",
    "    def do_stop(self): #signalled by a call back\n",
    "        try:     return self.stop\n",
    "        finally: self.stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining fit()\n",
    "def one_batch(x_minib, y_minib, callbacks):\n",
    "    if not callbacks.begin_batch(x_minib,y_minib):\n",
    "        return\n",
    "    loss = callbacks.loss_function(callbacks.model(x_minib), y_minib)\n",
    "    if not callbacks.after_loss(loss):\n",
    "        return\n",
    "    loss.backward()\n",
    "    if callbacks.after_backward(): \n",
    "        callbacks.optimizer.step()\n",
    "    if callbacks.after_step():\n",
    "        callbacks.optimizer.zero_grad()\n",
    "    \n",
    "def all_batches(dataloader, callbacks):\n",
    "    for x_minib, y_minib in dataloader:\n",
    "        one_batch(x_minib, y_minib, callbacks)\n",
    "        if callbacks.do_stop():\n",
    "            return\n",
    "    \n",
    "def fit(num_epochs, model, optimizer, loss_func, train_dataloader, valid_dataloader, callbacks):\n",
    "    if not callbacks.begin_fit(model, optimizer, loss_func, train_dataloader, valid_dataloader):\n",
    "        return\n",
    "    for epoch in range(num_epochs):\n",
    "        if not callbacks.begin_epoch(epoch):\n",
    "            continue\n",
    "        all_batches(train_dataloader, callbacks)\n",
    "        \n",
    "        if callbacks.begin_validate():\n",
    "            with torch.no_grad():\n",
    "                all_batches(valid_dataloader, callbacks)\n",
    "        if callbacks.do_stop() or not callbacks.after_epoch():\n",
    "            break\n",
    "        callbacks.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def begin_fit(self,model, opt, loss_func, train_dl, valid_dl):\n",
    "        super().begin_fit(model, opt, loss_func, train_dl, valid_dl)\n",
    "        self.n_iters = 0\n",
    "        return True\n",
    "        \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=10: \n",
    "            self.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple 3 layer example model\n",
    "\n",
    "def get_model(training_data, lr=0.5, nh=50):\n",
    "    m = training_data.x_dataset.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,categories))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_hidden = 50\n",
    "batch_size = 64\n",
    "loss_func = F.cross_entropy\n",
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "\n",
    "#setup data\n",
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, shuffle=False)\n",
    "categories = y_train.max().item()+1\n",
    "model, optimizer = get_model(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "fit(1, model, optimizer, loss_func, train_dl, valid_dl, callbacks=CallbackHandler([TestCallback()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Stream-lining the Callback Interface:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "def convert_to_list(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "#export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
    "\n",
    "def get_model(training_dl, lr=0.5, nh=50):\n",
    "    m = training_dl.x_dataset.shape[1]\n",
    "    categories = training_dl.y_dataset.max().item()+1\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,categories))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Refactored Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, runner): self.run=runner\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "\n",
    "#callback included in every runner, tracks iterations and epochs\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False\n",
    "\n",
    "#new version of test callback\n",
    "class TestCallback(Callback):\n",
    "    def after_step(self):\n",
    "        if self.train_eval.n_iters>=10:\n",
    "            return True #stops training with a True flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Statistics using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.metrics = convert_to_list(metrics)\n",
    "        self.in_train = in_train\n",
    "        \n",
    "    def reset(self):\n",
    "        self.total_loss = 0.\n",
    "        self.count = 0\n",
    "        self.total_metrics = [0.] * len(self.metrics)\n",
    "        \n",
    "    @property\n",
    "    def all_stats(self): \n",
    "        return [self.total_loss.item()] + self.total_metrics\n",
    "    @property\n",
    "    def avg_stats(self):\n",
    "        return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        batch_size = run.xb.shape[0]\n",
    "        self.total_loss += run.loss * batch_size\n",
    "        self.count += batch_size\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.total_metrics[i] += m(run.pred, run.yb) * batch_size\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats = AvgStats(metrics,True)\n",
    "        self.valid_stats = AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):        \n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad():\n",
    "            stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner: a class to wrap the core classes together and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_functions=None):\n",
    "        callbacks = convert_to_list(cbs)\n",
    "        for cbf in convert_to_list(cb_functions): #convert functions to callbacks\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            callbacks.append(cb)\n",
    "        self.stop = False\n",
    "        self.callbacks = [TrainEvalCallback()]+callbacks\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb,yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop=False\n",
    "\n",
    "    #the new training loop\n",
    "    def fit(self, epochs_in, model_in, optimizer_in, loss_function_in, train_dl_in, valid_dl_in):\n",
    "        self.epochs = epochs_in\n",
    "        self.model = model_in\n",
    "        self.opt = optimizer_in\n",
    "        self.loss_func = loss_function_in\n",
    "        self.train_dl = train_dl_in\n",
    "        self.valid_dl = valid_dl_in\n",
    "        try:\n",
    "            for cb in self.callbacks: cb.set_runner(self)\n",
    "            if self('begin_fit'): return\n",
    "            for epoch in range(self.epochs):\n",
    "                self.epoch = epoch\n",
    "                #training\n",
    "                if not self('begin_epoch'): #callbacks default to false returns\n",
    "                    self.all_batches(self.train_dl)\n",
    "                \n",
    "                #validation \n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): \n",
    "                        self.all_batches(self.valid_dl)\n",
    "                if self('after_epoch'): break\n",
    "            \n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.model = None\n",
    "            self.opt = None\n",
    "            self.loss_func = None\n",
    "            self.train_dl = None\n",
    "            self.valid_dl = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        for cb in sorted(self.callbacks, key=lambda x: x._order):\n",
    "            f = getattr(cb, cb_name, None)\n",
    "            if f and f():\n",
    "                return True\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.424024375, tensor(0.0993)]\n",
      "valid: [2.387219921875, tensor(0.1064)]\n",
      "train: [2.4178259375, tensor(0.1007)]\n",
      "valid: [2.4089341796875, tensor(0.1064)]\n"
     ]
    }
   ],
   "source": [
    "training_ds = Dataset(x_train, y_train)\n",
    "training_dl = DataLoader(training_ds, shuffle = True)\n",
    "validation_ds = Dataset(x_valid, y_valid)\n",
    "validation_dl = DataLoader(valid_ds, shuffle = False)\n",
    "\n",
    "mod, opt = get_model(training_ds)\n",
    "stats = AvgStatsCallback([accuracy])\n",
    "run = Runner(cbs=stats)\n",
    "run.fit(2, mod, opt, F.cross_entropy, training_dl, validation_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employing the use of Python Partials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.4177571875, tensor(0.1011)]\n",
      "valid: [2.434072265625, tensor(0.0961)]\n"
     ]
    }
   ],
   "source": [
    "accuracy_callback_func = partial(AvgStatsCallback, accuracy) #makes use of Runner's callback function conversion\n",
    "run = Runner(cb_functions = accuracy_callback_func)\n",
    "run.fit(1, mod, opt, F.cross_entropy, training_dl, validation_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.434072265625, tensor(0.0961)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.avg_stats.valid_stats.avg_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
